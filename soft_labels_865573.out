[Info] Running in Docker environment
I am process 1764602, running on gn1222.twcc.ai: starting (Thu Jan 22 21:17:16 2026)
[Debug] Configuration Loaded - data_train: /work/t113618009/ssast_hub/finetune_stratified_final/train.json
Using precomputed dataset (reading .pt files)...
Found label CSV at: /work/t113618009/ssast_hub/class_labels_indices.csv
Loaded Label Map: 12 classes with 12 mappings.
Found JSON at: /work/t113618009/ssast_hub/finetune_stratified_final/train.json
Found 1599 samples in JSON: /work/t113618009/ssast_hub/finetune_stratified_final/train.json
Final valid samples: 1599 (Missing: 0)
Found label CSV at: /work/t113618009/ssast_hub/class_labels_indices.csv
Loaded Label Map: 12 classes with 12 mappings.
Found JSON at: /work/t113618009/ssast_hub/finetune_stratified_final/val.json
Found 200 samples in JSON: /work/t113618009/ssast_hub/finetune_stratified_final/val.json
Final valid samples: 200 (Missing: 0)
Now train with precomputed with 1599 samples, evaluate with 200 samples
Using timm version: 0.4.5, bypassing version assertion for compatibility.
now load a SSL pretrained models from /work/t113618009/ssast_hub/exp/pretrain_test/models/audio_model.134.pth
Using timm version: 0.4.5, bypassing version assertion for compatibility.
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=10, time=10
fine-tuning number of patches=1212
Now starting fine-tuning for 40 epochs
running on cuda
Total parameter number is : 87.736 million
Total trainable parameter number is : 87.736 million
The mlp header uses 10 x larger lr
Total mlp parameter number is : 0.011 million
Total base parameter number is : 87.725 million
now training with precomputed, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x14c4ea10e3d0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2026-01-22 21:17:33.860627
current #epochs=1, #steps=0
Epoch: [1][100/133]	Per Sample Total Time 0.05103	Per Sample Data Time 0.00079	Per Sample DNN Time 0.05024	Train Loss 0.3109	
start validation
mAP: 0.598940
AUC: 0.844101
Avg Precision: 0.238016
Avg Recall: 1.000000
d_prime: 1.430413
train_loss: 0.294416
valid_loss: 0.695897
validation finished
normal learning rate scheduler step
Epoch-1 lr: 5e-05
Epoch-1 lr: 0.0005
epoch 1 training time: 87.062
---------------
2026-01-22 21:19:00.922563
current #epochs=2, #steps=133
Epoch: [2][67/133]	Per Sample Total Time 0.04904	Per Sample Data Time 0.00111	Per Sample DNN Time 0.04793	Train Loss 0.2219	
start validation
mAP: 0.640256
AUC: 0.882337
Avg Precision: 0.261381
Avg Recall: 1.000000
d_prime: 1.678320
train_loss: 0.212384
valid_loss: 0.685807
validation finished
normal learning rate scheduler step
Epoch-2 lr: 5e-05
Epoch-2 lr: 0.0005
epoch 2 training time: 83.653
---------------
2026-01-22 21:20:24.575472
current #epochs=3, #steps=266
Epoch: [3][34/133]	Per Sample Total Time 0.04979	Per Sample Data Time 0.00183	Per Sample DNN Time 0.04795	Train Loss 0.1823	
start validation
mAP: 0.699333
AUC: 0.915124
Avg Precision: 0.318698
Avg Recall: 1.000000
d_prime: 1.941715
train_loss: 0.184753
valid_loss: 0.681312
validation finished
normal learning rate scheduler step
Epoch-3 lr: 5e-05
Epoch-3 lr: 0.0005
epoch 3 training time: 83.656
---------------
2026-01-22 21:21:48.231320
current #epochs=4, #steps=399
Epoch: [4][1/133]	Per Sample Total Time 0.08056	Per Sample Data Time 0.02937	Per Sample DNN Time 0.05119	Train Loss 0.1640	
Epoch: [4][101/133]	Per Sample Total Time 0.04894	Per Sample Data Time 0.00089	Per Sample DNN Time 0.04805	Train Loss 0.1550	
start validation
mAP: 0.690661
AUC: 0.910710
Avg Precision: 0.289414
Avg Recall: 1.000000
d_prime: 1.902312
train_loss: 0.156741
valid_loss: 0.680580
validation finished
normal learning rate scheduler step
Epoch-4 lr: 5e-05
Epoch-4 lr: 0.0005
epoch 4 training time: 82.472
---------------
2026-01-22 21:23:10.703270
current #epochs=5, #steps=532
Epoch: [5][68/133]	Per Sample Total Time 0.04907	Per Sample Data Time 0.00105	Per Sample DNN Time 0.04802	Train Loss 0.1384	
start validation
mAP: 0.736986
AUC: 0.927391
Avg Precision: 0.297674
Avg Recall: 1.000000
d_prime: 2.059988
train_loss: 0.138337
valid_loss: 0.675965
validation finished
normal learning rate scheduler step
Epoch-5 lr: 5e-05
Epoch-5 lr: 0.0005
epoch 5 training time: 83.327
---------------
2026-01-22 21:24:34.030212
current #epochs=6, #steps=665
Epoch: [6][35/133]	Per Sample Total Time 0.04978	Per Sample Data Time 0.00179	Per Sample DNN Time 0.04799	Train Loss 0.1104	
start validation
mAP: 0.749752
AUC: 0.935287
Avg Precision: 0.287856
Avg Recall: 1.000000
d_prime: 2.144468
train_loss: 0.121385
valid_loss: 0.671050
validation finished
normal learning rate scheduler step
Epoch-6 lr: 5e-05
Epoch-6 lr: 0.0005
epoch 6 training time: 83.407
---------------
2026-01-22 21:25:57.437650
current #epochs=7, #steps=798
Epoch: [7][2/133]	Per Sample Total Time 0.06350	Per Sample Data Time 0.01547	Per Sample DNN Time 0.04803	Train Loss 0.1044	
Epoch: [7][102/133]	Per Sample Total Time 0.04881	Per Sample Data Time 0.00076	Per Sample DNN Time 0.04805	Train Loss 0.1021	
start validation
mAP: 0.717201
AUC: 0.921921
Avg Precision: 0.323092
Avg Recall: 1.000000
d_prime: 2.005518
train_loss: 0.105050
valid_loss: 0.676174
validation finished
normal learning rate scheduler step
Epoch-7 lr: 5e-05
Epoch-7 lr: 0.0005
epoch 7 training time: 82.297
---------------
2026-01-22 21:27:19.734987
current #epochs=8, #steps=931
Epoch: [8][69/133]	Per Sample Total Time 0.04910	Per Sample Data Time 0.00104	Per Sample DNN Time 0.04806	Train Loss 0.0924	
start validation
mAP: 0.733809
AUC: 0.917617
Avg Precision: 0.296157
Avg Recall: 1.000000
d_prime: 1.964650
train_loss: 0.094635
valid_loss: 0.673619
validation finished
normal learning rate scheduler step
Epoch-8 lr: 5e-05
Epoch-8 lr: 0.0005
epoch 8 training time: 82.215
---------------
2026-01-22 21:28:41.950273
current #epochs=9, #steps=1064
Epoch: [9][36/133]	Per Sample Total Time 0.04983	Per Sample Data Time 0.00169	Per Sample DNN Time 0.04815	Train Loss 0.0788	
start validation
mAP: 0.726600
AUC: 0.912113
Avg Precision: 0.327981
Avg Recall: 1.000000
d_prime: 1.914677
train_loss: 0.084465
valid_loss: 0.671051
validation finished
normal learning rate scheduler step
Epoch-9 lr: 5e-05
Epoch-9 lr: 0.0005
epoch 9 training time: 82.655
---------------
2026-01-22 21:30:04.605193
current #epochs=10, #steps=1197
Epoch: [10][3/133]	Per Sample Total Time 0.06311	Per Sample Data Time 0.01454	Per Sample DNN Time 0.04857	Train Loss 0.0768	
Epoch: [10][103/133]	Per Sample Total Time 0.04895	Per Sample Data Time 0.00088	Per Sample DNN Time 0.04807	Train Loss 0.0725	
start validation
mAP: 0.740890
AUC: 0.923489
Avg Precision: 0.317857
Avg Recall: 1.000000
d_prime: 2.020824
train_loss: 0.073800
valid_loss: 0.670116
validation finished
normal learning rate scheduler step
Epoch-10 lr: 2.5e-05
Epoch-10 lr: 0.00025
epoch 10 training time: 82.417
---------------
2026-01-22 21:31:27.022099
current #epochs=11, #steps=1330
Epoch: [11][70/133]	Per Sample Total Time 0.04931	Per Sample Data Time 0.00122	Per Sample DNN Time 0.04809	Train Loss 0.0551	
start validation
mAP: 0.734071
AUC: 0.920003
Avg Precision: 0.330761
Avg Recall: 1.000000
d_prime: 1.987096
train_loss: 0.053275
valid_loss: 0.669042
validation finished
normal learning rate scheduler step
Epoch-11 lr: 2.5e-05
Epoch-11 lr: 0.00025
epoch 11 training time: 82.470
---------------
2026-01-22 21:32:49.491741
current #epochs=12, #steps=1463
Epoch: [12][37/133]	Per Sample Total Time 0.05002	Per Sample Data Time 0.00186	Per Sample DNN Time 0.04816	Train Loss 0.0451	
start validation
mAP: 0.729244
AUC: 0.918862
Avg Precision: 0.326898
Avg Recall: 1.000000
d_prime: 1.976300
train_loss: 0.041658
valid_loss: 0.666451
validation finished
normal learning rate scheduler step
Epoch-12 lr: 2.5e-05
Epoch-12 lr: 0.00025
epoch 12 training time: 82.552
---------------
2026-01-22 21:34:12.044180
current #epochs=13, #steps=1596
Epoch: [13][4/133]	Per Sample Total Time 0.05860	Per Sample Data Time 0.01041	Per Sample DNN Time 0.04819	Train Loss 0.0400	
Epoch: [13][104/133]	Per Sample Total Time 0.04890	Per Sample Data Time 0.00081	Per Sample DNN Time 0.04809	Train Loss 0.0352	
start validation
mAP: 0.733360
AUC: 0.912795
Avg Precision: 0.331223
Avg Recall: 1.000000
d_prime: 1.920741
train_loss: 0.036229
valid_loss: 0.665336
validation finished
normal learning rate scheduler step
Epoch-13 lr: 2.5e-05
Epoch-13 lr: 0.00025
epoch 13 training time: 82.573
---------------
2026-01-22 21:35:34.616913
current #epochs=14, #steps=1729
Epoch: [14][71/133]	Per Sample Total Time 0.04917	Per Sample Data Time 0.00105	Per Sample DNN Time 0.04812	Train Loss 0.0322	
start validation
mAP: 0.726798
AUC: 0.910765
Avg Precision: 0.324055
Avg Recall: 1.000000
d_prime: 1.902801
train_loss: 0.032878
valid_loss: 0.664689
validation finished
normal learning rate scheduler step
Epoch-14 lr: 2.5e-05
Epoch-14 lr: 0.00025
epoch 14 training time: 82.401
---------------
2026-01-22 21:36:57.017918
current #epochs=15, #steps=1862
Epoch: [15][38/133]	Per Sample Total Time 0.04995	Per Sample Data Time 0.00169	Per Sample DNN Time 0.04826	Train Loss 0.0317	
start validation
mAP: 0.721349
AUC: 0.914876
Avg Precision: 0.317989
Avg Recall: 1.000000
d_prime: 1.939461
train_loss: 0.032117
valid_loss: 0.663838
validation finished
normal learning rate scheduler step
Epoch-15 lr: 1.25e-05
Epoch-15 lr: 0.000125
epoch 15 training time: 82.443
---------------
2026-01-22 21:38:19.461215
current #epochs=16, #steps=1995
Epoch: [16][5/133]	Per Sample Total Time 0.05900	Per Sample Data Time 0.01089	Per Sample DNN Time 0.04811	Train Loss 0.0299	
Epoch: [16][105/133]	Per Sample Total Time 0.04914	Per Sample Data Time 0.00100	Per Sample DNN Time 0.04814	Train Loss 0.0300	
start validation
mAP: 0.733128
AUC: 0.911873
Avg Precision: 0.316314
Avg Recall: 1.000000
d_prime: 1.912552
train_loss: 0.030426
valid_loss: 0.664365
validation finished
normal learning rate scheduler step
Epoch-16 lr: 1.25e-05
Epoch-16 lr: 0.000125
epoch 16 training time: 82.555
---------------
2026-01-22 21:39:42.016567
current #epochs=17, #steps=2128
Epoch: [17][72/133]	Per Sample Total Time 0.04913	Per Sample Data Time 0.00091	Per Sample DNN Time 0.04822	Train Loss 0.0276	
start validation
mAP: 0.734451
AUC: 0.911968
Avg Precision: 0.316199
Avg Recall: 1.000000
d_prime: 1.913394
train_loss: 0.027739
valid_loss: 0.663970
validation finished
normal learning rate scheduler step
Epoch-17 lr: 1.25e-05
Epoch-17 lr: 0.000125
epoch 17 training time: 82.332
---------------
2026-01-22 21:41:04.348347
current #epochs=18, #steps=2261
Epoch: [18][39/133]	Per Sample Total Time 0.04976	Per Sample Data Time 0.00154	Per Sample DNN Time 0.04822	Train Loss 0.0265	
start validation
mAP: 0.729143
AUC: 0.909641
Avg Precision: 0.322020
Avg Recall: 1.000000
d_prime: 1.892992
train_loss: 0.026600
valid_loss: 0.663752
validation finished
normal learning rate scheduler step
Epoch-18 lr: 1.25e-05
Epoch-18 lr: 0.000125
epoch 18 training time: 82.266
---------------
2026-01-22 21:42:26.614175
current #epochs=19, #steps=2394
Epoch: [19][6/133]	Per Sample Total Time 0.05467	Per Sample Data Time 0.00663	Per Sample DNN Time 0.04804	Train Loss 0.0255	
Epoch: [19][106/133]	Per Sample Total Time 0.04889	Per Sample Data Time 0.00077	Per Sample DNN Time 0.04813	Train Loss 0.0262	
start validation
mAP: 0.726952
AUC: 0.907484
Avg Precision: 0.316983
Avg Recall: 1.000000
d_prime: 1.874425
train_loss: 0.026164
valid_loss: 0.663827
validation finished
normal learning rate scheduler step
Epoch-19 lr: 1.25e-05
Epoch-19 lr: 0.000125
epoch 19 training time: 82.401
---------------
2026-01-22 21:43:49.015495
current #epochs=20, #steps=2527
Epoch: [20][73/133]	Per Sample Total Time 0.04914	Per Sample Data Time 0.00094	Per Sample DNN Time 0.04820	Train Loss 0.0263	
start validation
mAP: 0.729845
AUC: 0.907766
Avg Precision: 0.330166
Avg Recall: 1.000000
d_prime: 1.876838
train_loss: 0.025958
valid_loss: 0.663182
validation finished
normal learning rate scheduler step
Epoch-20 lr: 6.25e-06
Epoch-20 lr: 6.25e-05
epoch 20 training time: 82.461
---------------
2026-01-22 21:45:11.476337
current #epochs=21, #steps=2660
Epoch: [21][40/133]	Per Sample Total Time 0.04969	Per Sample Data Time 0.00150	Per Sample DNN Time 0.04820	Train Loss 0.0279	
start validation
mAP: 0.729642
AUC: 0.905936
Avg Precision: 0.339728
Avg Recall: 1.000000
d_prime: 1.861297
train_loss: 0.025769
valid_loss: 0.663137
validation finished
normal learning rate scheduler step
Epoch-21 lr: 6.25e-06
Epoch-21 lr: 6.25e-05
epoch 21 training time: 82.549
---------------
2026-01-22 21:46:34.025082
current #epochs=22, #steps=2793
Epoch: [22][7/133]	Per Sample Total Time 0.05516	Per Sample Data Time 0.00707	Per Sample DNN Time 0.04810	Train Loss 0.0192	
Epoch: [22][107/133]	Per Sample Total Time 0.04896	Per Sample Data Time 0.00082	Per Sample DNN Time 0.04814	Train Loss 0.0253	
start validation
mAP: 0.727931
AUC: 0.906845
Avg Precision: 0.333491
Avg Recall: 1.000000
d_prime: 1.868989
train_loss: 0.025196
valid_loss: 0.663213
validation finished
normal learning rate scheduler step
Epoch-22 lr: 6.25e-06
Epoch-22 lr: 6.25e-05
epoch 22 training time: 82.370
---------------
2026-01-22 21:47:56.395436
current #epochs=23, #steps=2926
Epoch: [23][74/133]	Per Sample Total Time 0.04919	Per Sample Data Time 0.00103	Per Sample DNN Time 0.04816	Train Loss 0.0260	
start validation
mAP: 0.728720
AUC: 0.906002
Avg Precision: 0.332507
Avg Recall: 1.000000
d_prime: 1.861858
train_loss: 0.024940
valid_loss: 0.663071
validation finished
normal learning rate scheduler step
Epoch-23 lr: 6.25e-06
Epoch-23 lr: 6.25e-05
epoch 23 training time: 82.351
---------------
2026-01-22 21:49:18.746495
current #epochs=24, #steps=3059
Epoch: [24][41/133]	Per Sample Total Time 0.04992	Per Sample Data Time 0.00172	Per Sample DNN Time 0.04820	Train Loss 0.0260	
start validation
mAP: 0.726621
AUC: 0.904784
Avg Precision: 0.332268
Avg Recall: 1.000000
d_prime: 1.851634
train_loss: 0.024768
valid_loss: 0.663097
validation finished
normal learning rate scheduler step
Epoch-24 lr: 6.25e-06
Epoch-24 lr: 6.25e-05
epoch 24 training time: 82.552
---------------
2026-01-22 21:50:41.298578
current #epochs=25, #steps=3192
Epoch: [25][8/133]	Per Sample Total Time 0.05399	Per Sample Data Time 0.00582	Per Sample DNN Time 0.04817	Train Loss 0.0228	
Epoch: [25][108/133]	Per Sample Total Time 0.04892	Per Sample Data Time 0.00078	Per Sample DNN Time 0.04814	Train Loss 0.0244	
start validation
mAP: 0.729368
AUC: 0.905317
Avg Precision: 0.333463
Avg Recall: 1.000000
d_prime: 1.856092
train_loss: 0.024682
valid_loss: 0.662955
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.125e-06
Epoch-25 lr: 3.125e-05
epoch 25 training time: 82.404
---------------
2026-01-22 21:52:03.702974
current #epochs=26, #steps=3325
Epoch: [26][75/133]	Per Sample Total Time 0.04930	Per Sample Data Time 0.00113	Per Sample DNN Time 0.04817	Train Loss 0.0252	
start validation
mAP: 0.726339
AUC: 0.904352
Avg Precision: 0.332441
Avg Recall: 1.000000
d_prime: 1.848028
train_loss: 0.024519
valid_loss: 0.662867
validation finished
normal learning rate scheduler step
Epoch-26 lr: 3.125e-06
Epoch-26 lr: 3.125e-05
epoch 26 training time: 82.576
---------------
2026-01-22 21:53:26.278581
current #epochs=27, #steps=3458
Epoch: [27][42/133]	Per Sample Total Time 0.05003	Per Sample Data Time 0.00177	Per Sample DNN Time 0.04826	Train Loss 0.0244	
start validation
mAP: 0.727672
AUC: 0.904131
Avg Precision: 0.333570
Avg Recall: 1.000000
d_prime: 1.846189
train_loss: 0.024460
valid_loss: 0.662853
validation finished
normal learning rate scheduler step
Epoch-27 lr: 3.125e-06
Epoch-27 lr: 3.125e-05
epoch 27 training time: 82.595
---------------
2026-01-22 21:54:48.873619
current #epochs=28, #steps=3591
Epoch: [28][9/133]	Per Sample Total Time 0.05344	Per Sample Data Time 0.00535	Per Sample DNN Time 0.04810	Train Loss 0.0228	
Epoch: [28][109/133]	Per Sample Total Time 0.04894	Per Sample Data Time 0.00080	Per Sample DNN Time 0.04814	Train Loss 0.0245	
start validation
mAP: 0.727152
AUC: 0.903795
Avg Precision: 0.333066
Avg Recall: 1.000000
d_prime: 1.843405
train_loss: 0.024368
valid_loss: 0.662825
validation finished
normal learning rate scheduler step
Epoch-28 lr: 3.125e-06
Epoch-28 lr: 3.125e-05
epoch 28 training time: 82.297
---------------
2026-01-22 21:56:11.171148
current #epochs=29, #steps=3724
Epoch: [29][76/133]	Per Sample Total Time 0.04916	Per Sample Data Time 0.00102	Per Sample DNN Time 0.04814	Train Loss 0.0248	
start validation
mAP: 0.727694
AUC: 0.903488
Avg Precision: 0.333028
Avg Recall: 1.000000
d_prime: 1.840857
train_loss: 0.024353
valid_loss: 0.662786
validation finished
normal learning rate scheduler step
Epoch-29 lr: 3.125e-06
Epoch-29 lr: 3.125e-05
epoch 29 training time: 82.416
---------------
2026-01-22 21:57:33.586696
current #epochs=30, #steps=3857
Epoch: [30][43/133]	Per Sample Total Time 0.04970	Per Sample Data Time 0.00148	Per Sample DNN Time 0.04822	Train Loss 0.0229	
start validation
mAP: 0.727270
AUC: 0.903246
Avg Precision: 0.333644
Avg Recall: 1.000000
d_prime: 1.838862
train_loss: 0.024235
valid_loss: 0.662772
validation finished
normal learning rate scheduler step
Epoch-30 lr: 1.5625e-06
Epoch-30 lr: 1.5625e-05
epoch 30 training time: 82.375
---------------
2026-01-22 21:58:55.961979
current #epochs=31, #steps=3990
Epoch: [31][10/133]	Per Sample Total Time 0.05339	Per Sample Data Time 0.00520	Per Sample DNN Time 0.04818	Train Loss 0.0282	
Epoch: [31][110/133]	Per Sample Total Time 0.04897	Per Sample Data Time 0.00081	Per Sample DNN Time 0.04816	Train Loss 0.0245	
start validation
mAP: 0.726796
AUC: 0.902864
Avg Precision: 0.334110
Avg Recall: 1.000000
d_prime: 1.835715
train_loss: 0.024258
valid_loss: 0.662730
validation finished
normal learning rate scheduler step
Epoch-31 lr: 1.5625e-06
Epoch-31 lr: 1.5625e-05
epoch 31 training time: 82.459
---------------
2026-01-22 22:00:18.420595
current #epochs=32, #steps=4123
Epoch: [32][77/133]	Per Sample Total Time 0.04915	Per Sample Data Time 0.00094	Per Sample DNN Time 0.04821	Train Loss 0.0248	
start validation
mAP: 0.727163
AUC: 0.902711
Avg Precision: 0.334523
Avg Recall: 1.000000
d_prime: 1.834457
train_loss: 0.024267
valid_loss: 0.662720
validation finished
normal learning rate scheduler step
Epoch-32 lr: 1.5625e-06
Epoch-32 lr: 1.5625e-05
epoch 32 training time: 82.483
---------------
2026-01-22 22:01:40.903278
current #epochs=33, #steps=4256
Epoch: [33][44/133]	Per Sample Total Time 0.04989	Per Sample Data Time 0.00169	Per Sample DNN Time 0.04820	Train Loss 0.0233	
start validation
mAP: 0.727034
AUC: 0.902629
Avg Precision: 0.334717
Avg Recall: 1.000000
d_prime: 1.833776
train_loss: 0.024241
valid_loss: 0.662702
validation finished
normal learning rate scheduler step
Epoch-33 lr: 1.5625e-06
Epoch-33 lr: 1.5625e-05
epoch 33 training time: 82.631
---------------
2026-01-22 22:03:03.534425
current #epochs=34, #steps=4389
Epoch: [34][11/133]	Per Sample Total Time 0.05220	Per Sample Data Time 0.00404	Per Sample DNN Time 0.04816	Train Loss 0.0218	
Epoch: [34][111/133]	Per Sample Total Time 0.04887	Per Sample Data Time 0.00074	Per Sample DNN Time 0.04814	Train Loss 0.0245	
start validation
mAP: 0.727152
AUC: 0.902643
Avg Precision: 0.334621
Avg Recall: 1.000000
d_prime: 1.833897
train_loss: 0.024146
valid_loss: 0.662689
validation finished
normal learning rate scheduler step
Epoch-34 lr: 1.5625e-06
Epoch-34 lr: 1.5625e-05
epoch 34 training time: 82.581
---------------
2026-01-22 22:04:26.115845
current #epochs=35, #steps=4522
Epoch: [35][78/133]	Per Sample Total Time 0.04909	Per Sample Data Time 0.00095	Per Sample DNN Time 0.04815	Train Loss 0.0251	
start validation
mAP: 0.726865
AUC: 0.902343
Avg Precision: 0.334717
Avg Recall: 1.000000
d_prime: 1.831434
train_loss: 0.024084
valid_loss: 0.662664
validation finished
normal learning rate scheduler step
Epoch-35 lr: 7.8125e-07
Epoch-35 lr: 7.8125e-06
epoch 35 training time: 82.458
---------------
2026-01-22 22:05:48.574341
current #epochs=36, #steps=4655
Epoch: [36][45/133]	Per Sample Total Time 0.04963	Per Sample Data Time 0.00141	Per Sample DNN Time 0.04823	Train Loss 0.0258	
start validation
mAP: 0.727278
AUC: 0.902437
Avg Precision: 0.334603
Avg Recall: 1.000000
d_prime: 1.832206
train_loss: 0.024131
valid_loss: 0.662650
validation finished
normal learning rate scheduler step
Epoch-36 lr: 7.8125e-07
Epoch-36 lr: 7.8125e-06
epoch 36 training time: 82.373
---------------
2026-01-22 22:07:10.946888
current #epochs=37, #steps=4788
Epoch: [37][12/133]	Per Sample Total Time 0.05275	Per Sample Data Time 0.00460	Per Sample DNN Time 0.04816	Train Loss 0.0236	
Epoch: [37][112/133]	Per Sample Total Time 0.04900	Per Sample Data Time 0.00084	Per Sample DNN Time 0.04816	Train Loss 0.0246	
start validation
mAP: 0.726809
AUC: 0.902421
Avg Precision: 0.334769
Avg Recall: 1.000000
d_prime: 1.832071
train_loss: 0.024152
valid_loss: 0.662628
validation finished
normal learning rate scheduler step
Epoch-37 lr: 7.8125e-07
Epoch-37 lr: 7.8125e-06
epoch 37 training time: 82.541
---------------
2026-01-22 22:08:33.487911
current #epochs=38, #steps=4921
Epoch: [38][79/133]	Per Sample Total Time 0.04910	Per Sample Data Time 0.00093	Per Sample DNN Time 0.04817	Train Loss 0.0233	
start validation
mAP: 0.726782
AUC: 0.902194
Avg Precision: 0.334539
Avg Recall: 1.000000
d_prime: 1.830211
train_loss: 0.024066
valid_loss: 0.662624
validation finished
normal learning rate scheduler step
Epoch-38 lr: 7.8125e-07
Epoch-38 lr: 7.8125e-06
epoch 38 training time: 82.358
---------------
2026-01-22 22:09:55.846063
current #epochs=39, #steps=5054
Epoch: [39][46/133]	Per Sample Total Time 0.04945	Per Sample Data Time 0.00125	Per Sample DNN Time 0.04820	Train Loss 0.0248	
start validation
mAP: 0.726780
AUC: 0.902178
Avg Precision: 0.335132
Avg Recall: 1.000000
d_prime: 1.830080
train_loss: 0.024087
valid_loss: 0.662597
validation finished
normal learning rate scheduler step
Epoch-39 lr: 7.8125e-07
Epoch-39 lr: 7.8125e-06
epoch 39 training time: 82.341
---------------
2026-01-22 22:11:18.186679
current #epochs=40, #steps=5187
Epoch: [40][13/133]	Per Sample Total Time 0.05195	Per Sample Data Time 0.00381	Per Sample DNN Time 0.04814	Train Loss 0.0248	
Epoch: [40][113/133]	Per Sample Total Time 0.04892	Per Sample Data Time 0.00077	Per Sample DNN Time 0.04815	Train Loss 0.0243	
start validation
mAP: 0.726732
AUC: 0.902066
Avg Precision: 0.334680
Avg Recall: 1.000000
d_prime: 1.829160
train_loss: 0.024108
valid_loss: 0.662603
validation finished
normal learning rate scheduler step
Epoch-40 lr: 3.90625e-07
Epoch-40 lr: 3.90625e-06
epoch 40 training time: 82.417
---------------evaluate on validation set---------------
---------------evaluate on evaluation set---------------
Found label CSV at: /work/t113618009/ssast_hub/class_labels_indices.csv
Loaded Label Map: 12 classes with 12 mappings.
Found JSON at: /work/t113618009/ssast_hub/finetune_stratified_final/test.json
Found 200 samples in JSON: /work/t113618009/ssast_hub/finetune_stratified_final/test.json
Final valid samples: 200 (Missing: 0)
