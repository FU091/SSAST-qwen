[Info] Running in Docker environment
I am process 3935957, running on gn1218.twcc.ai: starting (Wed Jan 28 22:53:06 2026)
[Debug] Configuration Loaded - data_train: /work/t113618009/ssast_hub/finetune_stratified_final/train.json
Using precomputed dataset (reading .pt files)...
Found label CSV at: /work/t113618009/ssast_hub/class_labels_indices.csv
Loaded Label Map: 12 classes with 12 mappings.
Found JSON at: /work/t113618009/ssast_hub/finetune_stratified_final/train.json
Found 1599 samples in JSON: /work/t113618009/ssast_hub/finetune_stratified_final/train.json
Final valid samples: 1599 (Missing: 0)
Found label CSV at: /work/t113618009/ssast_hub/class_labels_indices.csv
Loaded Label Map: 12 classes with 12 mappings.
Found JSON at: /work/t113618009/ssast_hub/finetune_stratified_final/val.json
Found 200 samples in JSON: /work/t113618009/ssast_hub/finetune_stratified_final/val.json
Final valid samples: 200 (Missing: 0)
Now train with precomputed with 1599 samples, evaluate with 200 samples
Using timm version: 0.4.5, bypassing version assertion for compatibility.
now load a SSL pretrained models from /work/t113618009/ssast_hub/exp/pretrain_fs_tml/models/best_audio_model.pth
Using timm version: 0.4.5, bypassing version assertion for compatibility.
pretraining patch split stride: frequency=16, time=16
pretraining patch shape: frequency=16, time=16
pretraining patch array dimension: frequency=8, time=64
pretraining number of patches=512
fine-tuning patch split stride: frequncey=10, time=10
fine-tuning number of patches=1212
Now starting fine-tuning for 40 epochs
running on cuda
Total parameter number is : 87.736 million
Total trainable parameter number is : 87.736 million
The mlp header uses 10 x larger lr
Total mlp parameter number is : 0.011 million
Total base parameter number is : 87.725 million
now training with precomputed, main metrics: mAP, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x14d85888e3d0>
The learning rate scheduler starts at 10 epoch with decay rate of 0.500 every 5 epoches
current #steps=0, #epochs=1
start training...
---------------
2026-01-28 22:53:21.066467
current #epochs=1, #steps=0
Epoch: [1][100/133]	Per Sample Total Time 0.05645	Per Sample Data Time 0.00085	Per Sample DNN Time 0.05560	Train Loss 0.3404	
start validation
mAP: 0.536988
AUC: 0.842838
Avg Precision: 0.226826
Avg Recall: 1.000000
d_prime: 1.422966
train_loss: 0.330479
valid_loss: 0.705604
validation finished
normal learning rate scheduler step
Epoch-1 lr: 5e-05
Epoch-1 lr: 0.0005
epoch 1 training time: 95.562
---------------
2026-01-28 22:54:56.628318
current #epochs=2, #steps=133
Epoch: [2][67/133]	Per Sample Total Time 0.05425	Per Sample Data Time 0.00123	Per Sample DNN Time 0.05301	Train Loss 0.2904	
start validation
mAP: 0.571382
AUC: 0.863575
Avg Precision: 0.247980
Avg Recall: 1.000000
d_prime: 1.550719
train_loss: 0.287102
valid_loss: 0.700659
validation finished
normal learning rate scheduler step
Epoch-2 lr: 5e-05
Epoch-2 lr: 0.0005
epoch 2 training time: 92.716
---------------
2026-01-28 22:56:29.344603
current #epochs=3, #steps=266
Epoch: [3][34/133]	Per Sample Total Time 0.05511	Per Sample Data Time 0.00211	Per Sample DNN Time 0.05300	Train Loss 0.2690	
start validation
mAP: 0.640301
AUC: 0.868397
Avg Precision: 0.264865
Avg Recall: 1.000000
d_prime: 1.582286
train_loss: 0.261443
valid_loss: 0.691996
validation finished
normal learning rate scheduler step
Epoch-3 lr: 5e-05
Epoch-3 lr: 0.0005
epoch 3 training time: 93.143
---------------
2026-01-28 22:58:02.487411
current #epochs=4, #steps=399
Epoch: [4][1/133]	Per Sample Total Time 0.08504	Per Sample Data Time 0.03187	Per Sample DNN Time 0.05317	Train Loss 0.2684	
Epoch: [4][101/133]	Per Sample Total Time 0.05412	Per Sample Data Time 0.00101	Per Sample DNN Time 0.05311	Train Loss 0.2592	
start validation
mAP: 0.671649
AUC: 0.894532
Avg Precision: 0.289123
Avg Recall: 1.000000
d_prime: 1.769176
train_loss: 0.259029
valid_loss: 0.691792
validation finished
normal learning rate scheduler step
Epoch-4 lr: 5e-05
Epoch-4 lr: 0.0005
epoch 4 training time: 92.840
---------------
2026-01-28 22:59:35.327359
current #epochs=5, #steps=532
Epoch: [5][68/133]	Per Sample Total Time 0.05446	Per Sample Data Time 0.00131	Per Sample DNN Time 0.05315	Train Loss 0.2467	
start validation
mAP: 0.686716
AUC: 0.886879
Avg Precision: 0.270564
Avg Recall: 1.000000
d_prime: 1.711335
train_loss: 0.249219
valid_loss: 0.691248
validation finished
normal learning rate scheduler step
Epoch-5 lr: 5e-05
Epoch-5 lr: 0.0005
epoch 5 training time: 92.846
---------------
2026-01-28 23:01:08.173447
current #epochs=6, #steps=665
Epoch: [6][35/133]	Per Sample Total Time 0.05514	Per Sample Data Time 0.00209	Per Sample DNN Time 0.05305	Train Loss 0.2440	
start validation
mAP: 0.693494
AUC: 0.894295
Avg Precision: 0.290950
Avg Recall: 1.000000
d_prime: 1.767336
train_loss: 0.241218
valid_loss: 0.687952
validation finished
normal learning rate scheduler step
Epoch-6 lr: 5e-05
Epoch-6 lr: 0.0005
epoch 6 training time: 92.730
---------------
2026-01-28 23:02:40.903039
current #epochs=7, #steps=798
Epoch: [7][2/133]	Per Sample Total Time 0.07356	Per Sample Data Time 0.02045	Per Sample DNN Time 0.05311	Train Loss 0.2329	
Epoch: [7][102/133]	Per Sample Total Time 0.05410	Per Sample Data Time 0.00096	Per Sample DNN Time 0.05314	Train Loss 0.2336	
start validation
mAP: 0.672522
AUC: 0.910773
Avg Precision: 0.303247
Avg Recall: 1.000000
d_prime: 1.902864
train_loss: 0.233825
valid_loss: 0.690449
validation finished
normal learning rate scheduler step
Epoch-7 lr: 5e-05
Epoch-7 lr: 0.0005
epoch 7 training time: 90.998
---------------
2026-01-28 23:04:11.901002
current #epochs=8, #steps=931
Epoch: [8][69/133]	Per Sample Total Time 0.05429	Per Sample Data Time 0.00114	Per Sample DNN Time 0.05314	Train Loss 0.2375	
start validation
mAP: 0.689279
AUC: 0.913509
Avg Precision: 0.321419
Avg Recall: 1.000000
d_prime: 1.927130
train_loss: 0.232524
valid_loss: 0.681623
validation finished
normal learning rate scheduler step
Epoch-8 lr: 5e-05
Epoch-8 lr: 0.0005
epoch 8 training time: 90.887
---------------
2026-01-28 23:05:42.788077
current #epochs=9, #steps=1064
Epoch: [9][36/133]	Per Sample Total Time 0.05495	Per Sample Data Time 0.00187	Per Sample DNN Time 0.05307	Train Loss 0.2325	
start validation
mAP: 0.701183
AUC: 0.923119
Avg Precision: 0.304974
Avg Recall: 1.000000
d_prime: 2.017191
train_loss: 0.228851
valid_loss: 0.679800
validation finished
normal learning rate scheduler step
Epoch-9 lr: 5e-05
Epoch-9 lr: 0.0005
epoch 9 training time: 92.426
---------------
2026-01-28 23:07:15.214112
current #epochs=10, #steps=1197
Epoch: [10][3/133]	Per Sample Total Time 0.06807	Per Sample Data Time 0.01495	Per Sample DNN Time 0.05312	Train Loss 0.2136	
Epoch: [10][103/133]	Per Sample Total Time 0.05401	Per Sample Data Time 0.00091	Per Sample DNN Time 0.05310	Train Loss 0.2158	
start validation
mAP: 0.715034
AUC: 0.912944
Avg Precision: 0.311966
Avg Recall: 1.000000
d_prime: 1.922070
train_loss: 0.214569
valid_loss: 0.679668
validation finished
normal learning rate scheduler step
Epoch-10 lr: 2.5e-05
Epoch-10 lr: 0.00025
epoch 10 training time: 92.526
---------------
2026-01-28 23:08:47.740240
current #epochs=11, #steps=1330
Epoch: [11][70/133]	Per Sample Total Time 0.05425	Per Sample Data Time 0.00115	Per Sample DNN Time 0.05310	Train Loss 0.2016	
start validation
mAP: 0.735911
AUC: 0.923980
Avg Precision: 0.332944
Avg Recall: 1.000000
d_prime: 2.025671
train_loss: 0.201394
valid_loss: 0.677478
validation finished
normal learning rate scheduler step
Epoch-11 lr: 2.5e-05
Epoch-11 lr: 0.00025
epoch 11 training time: 92.530
---------------
2026-01-28 23:10:20.270741
current #epochs=12, #steps=1463
Epoch: [12][37/133]	Per Sample Total Time 0.05497	Per Sample Data Time 0.00185	Per Sample DNN Time 0.05312	Train Loss 0.1955	
start validation
mAP: 0.756146
AUC: 0.919846
Avg Precision: 0.359416
Avg Recall: 1.000000
d_prime: 1.985612
train_loss: 0.199185
valid_loss: 0.676596
validation finished
normal learning rate scheduler step
Epoch-12 lr: 2.5e-05
Epoch-12 lr: 0.00025
epoch 12 training time: 92.692
---------------
2026-01-28 23:11:52.962594
current #epochs=13, #steps=1596
Epoch: [13][4/133]	Per Sample Total Time 0.06500	Per Sample Data Time 0.01181	Per Sample DNN Time 0.05319	Train Loss 0.2080	
Epoch: [13][104/133]	Per Sample Total Time 0.05407	Per Sample Data Time 0.00089	Per Sample DNN Time 0.05317	Train Loss 0.1931	
start validation
mAP: 0.739155
AUC: 0.910509
Avg Precision: 0.327729
Avg Recall: 1.000000
d_prime: 1.900559
train_loss: 0.194747
valid_loss: 0.673994
validation finished
normal learning rate scheduler step
Epoch-13 lr: 2.5e-05
Epoch-13 lr: 0.00025
epoch 13 training time: 90.976
---------------
2026-01-28 23:13:23.938243
current #epochs=14, #steps=1729
Epoch: [14][71/133]	Per Sample Total Time 0.05442	Per Sample Data Time 0.00121	Per Sample DNN Time 0.05321	Train Loss 0.1905	
start validation
mAP: 0.759540
AUC: 0.921789
Avg Precision: 0.344244
Avg Recall: 1.000000
d_prime: 2.004236
train_loss: 0.191273
valid_loss: 0.673418
validation finished
normal learning rate scheduler step
Epoch-14 lr: 2.5e-05
Epoch-14 lr: 0.00025
epoch 14 training time: 92.848
---------------
2026-01-28 23:14:56.786113
current #epochs=15, #steps=1862
Epoch: [15][38/133]	Per Sample Total Time 0.05562	Per Sample Data Time 0.00233	Per Sample DNN Time 0.05329	Train Loss 0.1875	
start validation
mAP: 0.756862
AUC: 0.919925
Avg Precision: 0.302610
Avg Recall: 1.000000
d_prime: 1.986362
train_loss: 0.188472
valid_loss: 0.671979
validation finished
normal learning rate scheduler step
Epoch-15 lr: 1.25e-05
Epoch-15 lr: 0.000125
epoch 15 training time: 91.542
---------------
2026-01-28 23:16:28.327770
current #epochs=16, #steps=1995
Epoch: [16][5/133]	Per Sample Total Time 0.06334	Per Sample Data Time 0.01019	Per Sample DNN Time 0.05315	Train Loss 0.1723	
Epoch: [16][105/133]	Per Sample Total Time 0.05411	Per Sample Data Time 0.00091	Per Sample DNN Time 0.05320	Train Loss 0.1798	
start validation
mAP: 0.756644
AUC: 0.913844
Avg Precision: 0.296030
Avg Recall: 1.000000
d_prime: 1.930138
train_loss: 0.178169
valid_loss: 0.671862
validation finished
normal learning rate scheduler step
Epoch-16 lr: 1.25e-05
Epoch-16 lr: 0.000125
epoch 16 training time: 91.047
---------------
2026-01-28 23:17:59.374929
current #epochs=17, #steps=2128
Epoch: [17][72/133]	Per Sample Total Time 0.05436	Per Sample Data Time 0.00113	Per Sample DNN Time 0.05322	Train Loss 0.1740	
start validation
mAP: 0.751930
AUC: 0.912572
Avg Precision: 0.284224
Avg Recall: 1.000000
d_prime: 1.918755
train_loss: 0.175338
valid_loss: 0.670703
validation finished
normal learning rate scheduler step
Epoch-17 lr: 1.25e-05
Epoch-17 lr: 0.000125
epoch 17 training time: 91.015
---------------
2026-01-28 23:19:30.390202
current #epochs=18, #steps=2261
Epoch: [18][39/133]	Per Sample Total Time 0.05505	Per Sample Data Time 0.00174	Per Sample DNN Time 0.05331	Train Loss 0.1754	
start validation
mAP: 0.761278
AUC: 0.917367
Avg Precision: 0.280566
Avg Recall: 1.000000
d_prime: 1.962328
train_loss: 0.174792
valid_loss: 0.669910
validation finished
normal learning rate scheduler step
Epoch-18 lr: 1.25e-05
Epoch-18 lr: 0.000125
epoch 18 training time: 92.970
---------------
2026-01-28 23:21:03.360693
current #epochs=19, #steps=2394
Epoch: [19][6/133]	Per Sample Total Time 0.06247	Per Sample Data Time 0.00927	Per Sample DNN Time 0.05319	Train Loss 0.1846	
Epoch: [19][106/133]	Per Sample Total Time 0.05418	Per Sample Data Time 0.00094	Per Sample DNN Time 0.05323	Train Loss 0.1700	
start validation
mAP: 0.749290
AUC: 0.917653
Avg Precision: 0.315948
Avg Recall: 1.000000
d_prime: 1.964984
train_loss: 0.167566
valid_loss: 0.672490
validation finished
normal learning rate scheduler step
Epoch-19 lr: 1.25e-05
Epoch-19 lr: 0.000125
epoch 19 training time: 91.185
---------------
2026-01-28 23:22:34.546155
current #epochs=20, #steps=2527
Epoch: [20][73/133]	Per Sample Total Time 0.05441	Per Sample Data Time 0.00115	Per Sample DNN Time 0.05326	Train Loss 0.1646	
start validation
mAP: 0.744980
AUC: 0.913863
Avg Precision: 0.278906
Avg Recall: 1.000000
d_prime: 1.930306
train_loss: 0.170459
valid_loss: 0.669828
validation finished
normal learning rate scheduler step
Epoch-20 lr: 6.25e-06
Epoch-20 lr: 6.25e-05
epoch 20 training time: 91.101
---------------
2026-01-28 23:24:05.647483
current #epochs=21, #steps=2660
Epoch: [21][40/133]	Per Sample Total Time 0.05502	Per Sample Data Time 0.00169	Per Sample DNN Time 0.05332	Train Loss 0.1698	
start validation
mAP: 0.744812
AUC: 0.914470
Avg Precision: 0.300246
Avg Recall: 1.000000
d_prime: 1.935783
train_loss: 0.161385
valid_loss: 0.670701
validation finished
normal learning rate scheduler step
Epoch-21 lr: 6.25e-06
Epoch-21 lr: 6.25e-05
epoch 21 training time: 91.074
---------------
2026-01-28 23:25:36.721165
current #epochs=22, #steps=2793
Epoch: [22][7/133]	Per Sample Total Time 0.06066	Per Sample Data Time 0.00745	Per Sample DNN Time 0.05321	Train Loss 0.1648	
Epoch: [22][107/133]	Per Sample Total Time 0.05409	Per Sample Data Time 0.00086	Per Sample DNN Time 0.05323	Train Loss 0.1617	
start validation
mAP: 0.749836
AUC: 0.914244
Avg Precision: 0.274007
Avg Recall: 1.000000
d_prime: 1.933744
train_loss: 0.163528
valid_loss: 0.671097
validation finished
normal learning rate scheduler step
Epoch-22 lr: 6.25e-06
Epoch-22 lr: 6.25e-05
epoch 22 training time: 91.087
---------------
2026-01-28 23:27:07.808512
current #epochs=23, #steps=2926
Epoch: [23][74/133]	Per Sample Total Time 0.05451	Per Sample Data Time 0.00126	Per Sample DNN Time 0.05325	Train Loss 0.1542	
start validation
mAP: 0.750398
AUC: 0.916761
Avg Precision: 0.271966
Avg Recall: 1.000000
d_prime: 1.956717
train_loss: 0.160479
valid_loss: 0.671060
validation finished
normal learning rate scheduler step
Epoch-23 lr: 6.25e-06
Epoch-23 lr: 6.25e-05
epoch 23 training time: 91.335
---------------
2026-01-28 23:28:39.143364
current #epochs=24, #steps=3059
Epoch: [24][41/133]	Per Sample Total Time 0.05501	Per Sample Data Time 0.00183	Per Sample DNN Time 0.05318	Train Loss 0.1575	
start validation
mAP: 0.749857
AUC: 0.914930
Avg Precision: 0.263546
Avg Recall: 1.000000
d_prime: 1.939953
train_loss: 0.155895
valid_loss: 0.669787
validation finished
normal learning rate scheduler step
Epoch-24 lr: 6.25e-06
Epoch-24 lr: 6.25e-05
epoch 24 training time: 91.276
---------------
2026-01-28 23:30:10.419601
current #epochs=25, #steps=3192
Epoch: [25][8/133]	Per Sample Total Time 0.06067	Per Sample Data Time 0.00747	Per Sample DNN Time 0.05320	Train Loss 0.1539	
Epoch: [25][108/133]	Per Sample Total Time 0.05416	Per Sample Data Time 0.00098	Per Sample DNN Time 0.05318	Train Loss 0.1538	
start validation
mAP: 0.753125
AUC: 0.916281
Avg Precision: 0.279404
Avg Recall: 1.000000
d_prime: 1.952294
train_loss: 0.152850
valid_loss: 0.670348
validation finished
normal learning rate scheduler step
Epoch-25 lr: 3.125e-06
Epoch-25 lr: 3.125e-05
epoch 25 training time: 91.220
---------------
2026-01-28 23:31:41.639546
current #epochs=26, #steps=3325
Epoch: [26][75/133]	Per Sample Total Time 0.05431	Per Sample Data Time 0.00114	Per Sample DNN Time 0.05317	Train Loss 0.1560	
start validation
mAP: 0.748113
AUC: 0.913362
Avg Precision: 0.270195
Avg Recall: 1.000000
d_prime: 1.925813
train_loss: 0.154678
valid_loss: 0.670866
validation finished
normal learning rate scheduler step
Epoch-26 lr: 3.125e-06
Epoch-26 lr: 3.125e-05
epoch 26 training time: 91.310
---------------
2026-01-28 23:33:12.949432
current #epochs=27, #steps=3458
Epoch: [27][42/133]	Per Sample Total Time 0.05521	Per Sample Data Time 0.00189	Per Sample DNN Time 0.05332	Train Loss 0.1551	
start validation
mAP: 0.748209
AUC: 0.913865
Avg Precision: 0.269933
Avg Recall: 1.000000
d_prime: 1.930321
train_loss: 0.152174
valid_loss: 0.670155
validation finished
normal learning rate scheduler step
Epoch-27 lr: 3.125e-06
Epoch-27 lr: 3.125e-05
epoch 27 training time: 91.342
---------------
2026-01-28 23:34:44.291679
current #epochs=28, #steps=3591
Epoch: [28][9/133]	Per Sample Total Time 0.06051	Per Sample Data Time 0.00731	Per Sample DNN Time 0.05320	Train Loss 0.1533	
Epoch: [28][109/133]	Per Sample Total Time 0.05425	Per Sample Data Time 0.00102	Per Sample DNN Time 0.05323	Train Loss 0.1547	
start validation
mAP: 0.747335
AUC: 0.910938
Avg Precision: 0.258421
Avg Recall: 1.000000
d_prime: 1.904317
train_loss: 0.155544
valid_loss: 0.669691
validation finished
normal learning rate scheduler step
Epoch-28 lr: 3.125e-06
Epoch-28 lr: 3.125e-05
epoch 28 training time: 91.499
---------------
2026-01-28 23:36:15.791021
current #epochs=29, #steps=3724
Epoch: [29][76/133]	Per Sample Total Time 0.05434	Per Sample Data Time 0.00116	Per Sample DNN Time 0.05318	Train Loss 0.1517	
start validation
mAP: 0.746955
AUC: 0.910607
Avg Precision: 0.266137
Avg Recall: 1.000000
d_prime: 1.901416
train_loss: 0.151803
valid_loss: 0.669185
validation finished
normal learning rate scheduler step
Epoch-29 lr: 3.125e-06
Epoch-29 lr: 3.125e-05
epoch 29 training time: 91.267
---------------
2026-01-28 23:37:47.058444
current #epochs=30, #steps=3857
Epoch: [30][43/133]	Per Sample Total Time 0.05499	Per Sample Data Time 0.00182	Per Sample DNN Time 0.05317	Train Loss 0.1477	
start validation
mAP: 0.750175
AUC: 0.910909
Avg Precision: 0.268483
Avg Recall: 1.000000
d_prime: 1.904056
train_loss: 0.150990
valid_loss: 0.669245
validation finished
normal learning rate scheduler step
Epoch-30 lr: 1.5625e-06
Epoch-30 lr: 1.5625e-05
epoch 30 training time: 91.377
---------------
2026-01-28 23:39:18.435593
current #epochs=31, #steps=3990
Epoch: [31][10/133]	Per Sample Total Time 0.05902	Per Sample Data Time 0.00581	Per Sample DNN Time 0.05322	Train Loss 0.1468	
Epoch: [31][110/133]	Per Sample Total Time 0.05424	Per Sample Data Time 0.00096	Per Sample DNN Time 0.05328	Train Loss 0.1534	
start validation
mAP: 0.748921
AUC: 0.910981
Avg Precision: 0.263335
Avg Recall: 1.000000
d_prime: 1.904695
train_loss: 0.152965
valid_loss: 0.669333
validation finished
normal learning rate scheduler step
Epoch-31 lr: 1.5625e-06
Epoch-31 lr: 1.5625e-05
epoch 31 training time: 91.433
---------------
2026-01-28 23:40:49.869023
current #epochs=32, #steps=4123
Epoch: [32][77/133]	Per Sample Total Time 0.05448	Per Sample Data Time 0.00123	Per Sample DNN Time 0.05325	Train Loss 0.1534	
start validation
mAP: 0.746613
AUC: 0.911441
Avg Precision: 0.274633
Avg Recall: 1.000000
d_prime: 1.908741
train_loss: 0.154433
valid_loss: 0.669408
validation finished
normal learning rate scheduler step
Epoch-32 lr: 1.5625e-06
Epoch-32 lr: 1.5625e-05
epoch 32 training time: 91.398
---------------
2026-01-28 23:42:21.267125
current #epochs=33, #steps=4256
Epoch: [33][44/133]	Per Sample Total Time 0.05502	Per Sample Data Time 0.00168	Per Sample DNN Time 0.05334	Train Loss 0.1390	
start validation
mAP: 0.746521
AUC: 0.910656
Avg Precision: 0.268641
Avg Recall: 1.000000
d_prime: 1.901845
train_loss: 0.148491
valid_loss: 0.669232
validation finished
normal learning rate scheduler step
Epoch-33 lr: 1.5625e-06
Epoch-33 lr: 1.5625e-05
epoch 33 training time: 91.266
---------------
2026-01-28 23:43:52.533387
current #epochs=34, #steps=4389
Epoch: [34][11/133]	Per Sample Total Time 0.05833	Per Sample Data Time 0.00513	Per Sample DNN Time 0.05320	Train Loss 0.1580	
Epoch: [34][111/133]	Per Sample Total Time 0.05413	Per Sample Data Time 0.00090	Per Sample DNN Time 0.05323	Train Loss 0.1542	
start validation
mAP: 0.747881
AUC: 0.912982
Avg Precision: 0.276232
Avg Recall: 1.000000
d_prime: 1.922414
train_loss: 0.152799
valid_loss: 0.669693
validation finished
normal learning rate scheduler step
Epoch-34 lr: 1.5625e-06
Epoch-34 lr: 1.5625e-05
epoch 34 training time: 91.249
---------------
2026-01-28 23:45:23.782270
current #epochs=35, #steps=4522
Epoch: [35][78/133]	Per Sample Total Time 0.05444	Per Sample Data Time 0.00118	Per Sample DNN Time 0.05326	Train Loss 0.1562	
start validation
mAP: 0.751074
AUC: 0.912542
Avg Precision: 0.272203
Avg Recall: 1.000000
d_prime: 1.918486
train_loss: 0.153038
valid_loss: 0.669701
validation finished
normal learning rate scheduler step
Epoch-35 lr: 7.8125e-07
Epoch-35 lr: 7.8125e-06
epoch 35 training time: 91.445
---------------
2026-01-28 23:46:55.227085
current #epochs=36, #steps=4655
Epoch: [36][45/133]	Per Sample Total Time 0.05500	Per Sample Data Time 0.00169	Per Sample DNN Time 0.05331	Train Loss 0.1550	
start validation
mAP: 0.749992
AUC: 0.912057
Avg Precision: 0.269174
Avg Recall: 1.000000
d_prime: 1.914180
train_loss: 0.153426
valid_loss: 0.669693
validation finished
normal learning rate scheduler step
Epoch-36 lr: 7.8125e-07
Epoch-36 lr: 7.8125e-06
epoch 36 training time: 91.368
---------------
2026-01-28 23:48:26.594929
current #epochs=37, #steps=4788
Epoch: [37][12/133]	Per Sample Total Time 0.05859	Per Sample Data Time 0.00541	Per Sample DNN Time 0.05318	Train Loss 0.1314	
Epoch: [37][112/133]	Per Sample Total Time 0.05419	Per Sample Data Time 0.00096	Per Sample DNN Time 0.05323	Train Loss 0.1478	
start validation
mAP: 0.748739
AUC: 0.911986
Avg Precision: 0.264937
Avg Recall: 1.000000
d_prime: 1.913550
train_loss: 0.148288
valid_loss: 0.669098
validation finished
normal learning rate scheduler step
Epoch-37 lr: 7.8125e-07
Epoch-37 lr: 7.8125e-06
epoch 37 training time: 91.249
---------------
2026-01-28 23:49:57.843980
current #epochs=38, #steps=4921
Epoch: [38][79/133]	Per Sample Total Time 0.05483	Per Sample Data Time 0.00157	Per Sample DNN Time 0.05326	Train Loss 0.1485	
start validation
mAP: 0.748210
AUC: 0.912013
Avg Precision: 0.264148
Avg Recall: 1.000000
d_prime: 1.913792
train_loss: 0.153286
valid_loss: 0.668754
validation finished
normal learning rate scheduler step
Epoch-38 lr: 7.8125e-07
Epoch-38 lr: 7.8125e-06
epoch 38 training time: 91.806
---------------
2026-01-28 23:51:29.649834
current #epochs=39, #steps=5054
Epoch: [39][46/133]	Per Sample Total Time 0.05510	Per Sample Data Time 0.00179	Per Sample DNN Time 0.05331	Train Loss 0.1550	
start validation
mAP: 0.747539
AUC: 0.911015
Avg Precision: 0.260302
Avg Recall: 1.000000
d_prime: 1.904994
train_loss: 0.148718
valid_loss: 0.668674
validation finished
normal learning rate scheduler step
Epoch-39 lr: 7.8125e-07
Epoch-39 lr: 7.8125e-06
epoch 39 training time: 91.700
---------------
2026-01-28 23:53:01.350235
current #epochs=40, #steps=5187
Epoch: [40][13/133]	Per Sample Total Time 0.05780	Per Sample Data Time 0.00460	Per Sample DNN Time 0.05320	Train Loss 0.1668	
Epoch: [40][113/133]	Per Sample Total Time 0.05414	Per Sample Data Time 0.00092	Per Sample DNN Time 0.05322	Train Loss 0.1596	
start validation
mAP: 0.748717
AUC: 0.911301
Avg Precision: 0.259228
Avg Recall: 1.000000
d_prime: 1.907501
train_loss: 0.156903
valid_loss: 0.669246
validation finished
normal learning rate scheduler step
Epoch-40 lr: 3.90625e-07
Epoch-40 lr: 3.90625e-06
epoch 40 training time: 91.342
---------------evaluate on validation set---------------
---------------evaluate on evaluation set---------------
Found label CSV at: /work/t113618009/ssast_hub/class_labels_indices.csv
Loaded Label Map: 12 classes with 12 mappings.
Found JSON at: /work/t113618009/ssast_hub/finetune_stratified_final/test.json
Found 200 samples in JSON: /work/t113618009/ssast_hub/finetune_stratified_final/test.json
Final valid samples: 200 (Missing: 0)
